{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99bf62bb",
   "metadata": {},
   "source": [
    "This code is for simulate unified random sampler distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b76c775",
   "metadata": {},
   "source": [
    "https://openfhe-development.readthedocs.io/en/latest/sphinx_rsts/modules/core/math/core_math.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d273f37",
   "metadata": {},
   "source": [
    "### üéØ **What Is Random Sampling?**\n",
    "\n",
    "> **Random sampling** is the process of **selecting values from a probability distribution** such that each value is chosen **according to its probability** in that distribution.\n",
    "\n",
    "In other words:  \n",
    "- You have a **target distribution** (e.g., Gaussian, uniform, ternary)  \n",
    "- You use a **source of randomness** (e.g., PRNG)  \n",
    "- You **transform** that randomness to **match the target distribution**\n",
    "\n",
    "---\n",
    "\n",
    "### üîÅ The General Process\n",
    "\n",
    "```text\n",
    "[Uniform Random Bits] \n",
    "        ‚Üì\n",
    "[Sampling Algorithm]\n",
    "        ‚Üì\n",
    "[Sample from Target Distribution]\n",
    "```\n",
    "\n",
    "- **Input**: High-quality uniform random bits (e.g., from ChaCha20)\n",
    "- **Output**: A number that follows your desired distribution (e.g., Gaussian noise for FHE)\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Common Distributions in FHE\n",
    "\n",
    "| Distribution | What It Looks Like | Used For |\n",
    "|-------------|-------------------|--------|\n",
    "| **Uniform** | All values equally likely | Public key masks (`a`) |\n",
    "| **Discrete Gaussian** | Bell curve over integers | Error terms (`e`) ‚Äî **critical for security** |\n",
    "| **Ternary** | Only {‚àí1, 0, +1} | Secret keys (`s`) in CKKS/TFHE |\n",
    "\n",
    "---\n",
    "\n",
    "### üîß How Sampling Works (Examples)\n",
    "\n",
    "#### 1. **Uniform Sampling in ‚Ñ§_q**\n",
    "- **Goal**: Pick random number in {0, 1, ..., q‚àí1}\n",
    "- **Method**: Use rejection sampling to avoid bias\n",
    "  ```python\n",
    "  while True:\n",
    "      r = prng.get_bits(k)  # k = ceil(log2(q))\n",
    "      if r < q: return r\n",
    "  ```\n",
    "\n",
    "#### 2. **Discrete Gaussian Sampling**\n",
    "- **Goal**: Pick small integers with bell-shaped probabilities\n",
    "- **Method**: CDT (Cumulative Distribution Table) + binary search\n",
    "  - Precompute CDF for œÉ = 3.2\n",
    "  - Generate uniform `u ‚àà [0,1)`\n",
    "  - Find `x` where `CDF[x] > u`\n",
    "\n",
    "#### 3. **Ternary Sampling**\n",
    "- **Goal**: Output ‚àí1, 0, or +1 with specific probabilities\n",
    "- **Method**: Threshold comparison\n",
    "  ```python\n",
    "  u = prng.get_bits(16)\n",
    "  if u < p0 * 65536: return 0\n",
    "  elif u < (p0 + p1) * 65536: return +1\n",
    "  else: return -1\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Why \"Random\" Isn‚Äôt Enough\n",
    "\n",
    "You **can‚Äôt just use raw PRNG output** ‚Äî because:\n",
    "- PRNG gives **uniform bits**\n",
    "- FHE needs **structured randomness** (Gaussian, ternary, etc.)\n",
    "- **Wrong distribution ‚Üí insecure or broken FHE**\n",
    "\n",
    "> üîê **Security depends on correct sampling!**  \n",
    "> If your Gaussian sampler is biased, lattice attacks can recover the secret key.\n",
    "\n",
    "---\n",
    "\n",
    "### üß© Random Sampling in Your FHE Hardware\n",
    "\n",
    "In your unified sampler:\n",
    "- **Input**: 256-bit seed ‚Üí ChaCha20 ‚Üí uniform 32/64-bit words\n",
    "- **Processing**: \n",
    "  - For **Gaussian**: CDT lookup\n",
    "  - For **Ternary**: threshold compare  \n",
    "  - For **Uniform**: rejection sampling\n",
    "- **Output**: FHE-ready samples for key generation\n",
    "\n",
    "This is **exactly what OpenFHE, SEAL, and PALISADE do in software** ‚Äî you‚Äôre just doing it **faster in hardware**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary\n",
    "\n",
    "> **Random sampling = transforming uniform randomness into a specific probability distribution.**  \n",
    "> \n",
    "> In FHE, it‚Äôs **not optional** ‚Äî it‚Äôs **essential** for:\n",
    "> - **Security** (hard lattice problems)\n",
    "> - **Correctness** (controlled noise growth)\n",
    "> - **Functionality** (key generation, encryption)\n",
    "\n",
    "Your unified hardware sampler **solves a real bottleneck** by doing this efficiently for **multiple distributions** in one core.\n",
    "\n",
    "You‚Äôre building a **critical component** of practical FHE systems! üõ†Ô∏è‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf379131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python reference for a Unified Random Sampler (Uniform, Ternary, Discrete Gaussian via CDT)\n",
    "# Author: Muhammad Ogin Hasanuddin\n",
    "# Requirements: numpy\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05a920da",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = np.array([281474976317441, 140737518764033, 140737470791681, 140737513783297,\n",
    "        140737471578113, 140737513259009, 140737471971329, 140737509851137,\n",
    "        140737480359937, 140737509457921, 140737481801729, 140737508671489,\n",
    "        140737482981377, 140737506705409, 140737483898881, 140737504608257,\n",
    "        140737484685313, 140737499496449, 140737485864961, 140737493729281,\n",
    "        140737486520321, 140737490976769, 140737487306753, 140737488486401,\n",
    "        281474975662081, 281474974482433, 281474966880257, 281474962554881,\n",
    "        281474960326657, 281474957180929, 281474955476993, 281474952462337],\n",
    "       dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8c84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7138484576005690180 4047939128787533792 7919168045412322066 ...\n",
      " 5165126301894588549 1116274645351253783 8585293112977999438]\n",
      "100000\n",
      "281474976317441\n",
      "100000\n",
      "[Uniform] min,max = 1606586509 281473775160182\n",
      "[Uniform] unique coverage fraction ~ 0.9999900248902984\n",
      "[Ternary] P(-1)=0.2522, P(0)=0.4981, P(+1)=0.2497\n",
      "[Gaussian] mean=-0.0023, std‚âà1.1116\n",
      "[Gaussian] P(x=0)=0.4750, P(x>0)=0.2614, P(x<0)=0.2636\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Helpers (Barrett reduce, etc.)\n",
    "# ------------------------------\n",
    "def barrett_reduce(x: np.ndarray, q: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reference Barrett reduction (64-bit) for demonstration.\n",
    "    In hardware you'd choose k so that 2^k > q^2. Here we use k=64.\n",
    "    \"\"\"\n",
    "    k = 64\n",
    "    mu = (1 << k) // q\n",
    "    # Ensure x is unsigned 128-ish via Python big ints, apply vectorized formula\n",
    "    t = ((x.astype(object) * mu) >> k).astype(object)\n",
    "    r = (x.astype(object) - t * q).astype(int)\n",
    "    # One correction step (r in [0, 2q))\n",
    "    r = np.where(r >= q, r - q, r)\n",
    "    r = np.where(r < 0, r + q, r)\n",
    "    return r.astype(np.int64)\n",
    "\n",
    "# ------------------------------\n",
    "# Discrete Gaussian via CDT\n",
    "# ------------------------------\n",
    "@dataclass\n",
    "class GaussianCDTTable:\n",
    "    sigma: float\n",
    "    tail_sigma: float = 10.0  # truncate at ~10*sigma by default\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Build nonnegative-side probabilities P[X = k] ‚àù exp(-pi * k^2 / sigma^2)\n",
    "        # for k >= 0 (we will add sign later; note that k=0 is unique).\n",
    "        tmax = max(20, int(math.ceil(self.tail_sigma * self.sigma)))\n",
    "        ks = np.arange(0, tmax + 1, dtype=np.int64)\n",
    "        rho = np.exp(-math.pi * (ks.astype(np.float64) ** 2) / (self.sigma ** 2))\n",
    "        # Normalize for nonnegative side (we sample k >= 0; sign handled after)\n",
    "        Z = rho.sum()\n",
    "        p = rho / Z  # P_nonneg[k]\n",
    "        cdf = np.cumsum(p)\n",
    "        cdf[-1] = 1.0  # guard against float drift\n",
    "        self.ks = ks\n",
    "        self.cdf = cdf\n",
    "\n",
    "    def sample_nonneg(self, n: int, rng: np.random.Generator) -> np.ndarray:\n",
    "        u = rng.random(n)\n",
    "        idx = np.searchsorted(self.cdf, u, side=\"left\")\n",
    "        return self.ks[idx]\n",
    "\n",
    "def sample_discrete_gaussian_cdt(n: int, sigma: float, tail_sigma: float = 10.0,\n",
    "                                 rng: np.random.Generator | None = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Two-sided discrete Gaussian via CDT on the nonnegative side + random sign.\n",
    "    Returns integer samples with stddev approximately sigma (tail truncated).\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    table = GaussianCDTTable(sigma=sigma, tail_sigma=tail_sigma)\n",
    "    k = table.sample_nonneg(n, rng)\n",
    "    # random sign for k>0 (k=0 stays 0)\n",
    "    s = rng.integers(0, 2, size=n, dtype=np.int8) * 2 - 1  # in {-1, +1}\n",
    "    x = (k * s).astype(np.int64)\n",
    "    x[k == 0] = 0\n",
    "    return x\n",
    "\n",
    "# ------------------------------\n",
    "# Ternary sampler\n",
    "# ------------------------------\n",
    "def sample_ternary(n: int,\n",
    "                   p_minus: float = 0.25,\n",
    "                   p_zero: float = 0.50,\n",
    "                   p_plus: float = 0.25,\n",
    "                   rng: np.random.Generator | None = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ternary sampling for coefficients in {-1, 0, +1} with given probabilities.\n",
    "    Probabilities must sum to 1. Vectorized.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    if abs((p_minus + p_zero + p_plus) - 1.0) > 1e-12:\n",
    "        raise ValueError(\"Probabilities must sum to 1.\")\n",
    "    edges = np.array([p_minus, p_minus + p_zero], dtype=np.float64)\n",
    "    u = rng.random(n)\n",
    "    out = np.empty(n, dtype=np.int8)\n",
    "    out[:] = 1\n",
    "    out[u < edges[0]] = -1\n",
    "    out[(u >= edges[0]) & (u < edges[1])] = 0\n",
    "    return out.astype(np.int8)\n",
    "\n",
    "# ------------------------------\n",
    "# Uniform mod-q sampler\n",
    "# ------------------------------\n",
    "def sample_uniform_mod_q(n: int, q: int, use_barrett: bool = False,\n",
    "                         rng: np.random.Generator | None = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Uniform residues in [0, q). The hardware typically uses Barrett; for\n",
    "    Python we can use x % q or enable barrett for parity with RTL.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    # Draw 64-bit randoms (as if from a PRNG/TRNG) and reduce mod q\n",
    "    raw = rng.integers(0, 1 << 63, size=n, dtype=np.int64)\n",
    "    if use_barrett:\n",
    "        return barrett_reduce(raw, q)\n",
    "    else:\n",
    "        return (raw % q).astype(np.int64)\n",
    "\n",
    "# ------------------------------\n",
    "# Unified interface\n",
    "# ------------------------------\n",
    "class UnifiedSampler:\n",
    "    \"\"\"\n",
    "    Unified sampler with three modes: 'uniform', 'ternary', 'gaussian'.\n",
    "    Emulates a mode-selectable hardware sampler sharing one entropy source.\n",
    "    \"\"\"\n",
    "    def __init__(self, seed: int | None = None):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def sample(self, mode: str, n: int,\n",
    "               q: int | None = None,\n",
    "               p_minus: float = 0.25, p_zero: float = 0.50, p_plus: float = 0.25,\n",
    "               sigma: float = 3.2, tail_sigma: float = 10.0,\n",
    "               use_barrett: bool = False) -> np.ndarray:\n",
    "        mode = mode.lower()\n",
    "        if mode == \"uniform\":\n",
    "            if q is None:\n",
    "                raise ValueError(\"Uniform mode requires modulus q.\")\n",
    "            return sample_uniform_mod_q(n, q, use_barrett=use_barrett, rng=self.rng)\n",
    "        elif mode == \"ternary\":\n",
    "            return sample_ternary(n, p_minus=p_minus, p_zero=p_zero, p_plus=p_plus, rng=self.rng)\n",
    "        elif mode == \"gaussian\":\n",
    "            return sample_discrete_gaussian_cdt(n, sigma=sigma, tail_sigma=tail_sigma, rng=self.rng)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown mode. Use 'uniform', 'ternary', or 'gaussian'.\")\n",
    "\n",
    "# ------------------------------\n",
    "# Example usage / quick sanity checks\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    us = UnifiedSampler(seed=42)\n",
    "\n",
    "    # 1) Uniform mod-q\n",
    "    q = qp[0]\n",
    "    u = us.sample(\"uniform\", n=100_000, q=q)\n",
    "    print(\"[Uniform] min,max =\", int(u.min()), int(u.max()))\n",
    "    print(\"[Uniform] unique coverage fraction ~\", np.ptp(u.astype(np.int64)) / (q - 1))\n",
    "\n",
    "    # 2) Ternary with 1:2:1\n",
    "    t = us.sample(\"ternary\", n=100_000, p_minus=0.25, p_zero=0.50, p_plus=0.25)\n",
    "    p_m = (t == -1).mean()\n",
    "    p_0 = (t == 0).mean()\n",
    "    p_p = (t == +1).mean()\n",
    "    print(f\"[Ternary] P(-1)={p_m:.4f}, P(0)={p_0:.4f}, P(+1)={p_p:.4f}\")\n",
    "\n",
    "    # 3) Discrete Gaussian via CDT\n",
    "    g = us.sample(\"gaussian\", n=100_000, sigma=3.2, tail_sigma=10.0)\n",
    "    print(f\"[Gaussian] mean={g.mean():.4f}, std‚âà{g.std(ddof=0):.4f}\")\n",
    "    # crude symmetry check:\n",
    "    print(f\"[Gaussian] P(x=0)={np.mean(g==0):.4f}, P(x>0)={np.mean(g>0):.4f}, P(x<0)={np.mean(g<0):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa183cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bin(7138484576005690180)[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "184397a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Uniform] min,max = 1606586509 281473223078266\n",
      "[Uniform] unique coverage fraction ~ 0.999988063501321\n",
      "[Ternary] P(-1)=0.2498, P(0)=0.5017, P(+1)=0.2485\n",
      "[0 0 0 ... 3 1 1]\n",
      "[ 1 -1 -1 ... -1  1  1]\n",
      "[ 0  0  0 ... -3  1  1]\n",
      "[Gaussian] mean=0.0010, std‚âà1.1138\n",
      "[Gaussian] P(x=0)=0.4793, P(x>0)=0.2604, P(x<0)=0.2603\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Helpers (Barrett reduce, etc.)\n",
    "# ------------------------------\n",
    "def barrett_reduce(x: np.ndarray, q: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Reference Barrett reduction (64-bit) for demonstration.\n",
    "    In hardware you'd choose k so that 2^k > q^2. Here we use k=64.\n",
    "    \"\"\"\n",
    "    k = 64\n",
    "    mu = (1 << k) // q\n",
    "    # Ensure x is unsigned 128-ish via Python big ints, apply vectorized formula\n",
    "    t = ((x.astype(object) * mu) >> k).astype(object)\n",
    "    r = (x.astype(object) - t * q).astype(int)\n",
    "    # One correction step (r in [0, 2q))\n",
    "    r = np.where(r >= q, r - q, r)\n",
    "    r = np.where(r < 0, r + q, r)\n",
    "    return r.astype(np.int64)\n",
    "\n",
    "# ------------------------------\n",
    "# Discrete Gaussian via CDT\n",
    "# ------------------------------\n",
    "@dataclass\n",
    "class GaussianCDTTable:\n",
    "    sigma: float\n",
    "    tail_sigma: float = 10.0  # truncate at ~10*sigma by default\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Build nonnegative-side probabilities P[X = k] ‚àù exp(-pi * k^2 / sigma^2)\n",
    "        # for k >= 0 (we will add sign later; note that k=0 is unique).\n",
    "        tmax = max(20, int(math.ceil(self.tail_sigma * self.sigma)))\n",
    "        ks = np.arange(0, tmax + 1, dtype=np.int64)\n",
    "        rho = np.exp(-math.pi * (ks.astype(np.float64) ** 2) / (self.sigma ** 2))\n",
    "        # Normalize for nonnegative side (we sample k >= 0; sign handled after)\n",
    "        Z = rho.sum()\n",
    "        p = rho / Z  # P_nonneg[k]\n",
    "        cdf = np.cumsum(p)\n",
    "        cdf[-1] = 1.0  # guard against float drift\n",
    "        self.ks = ks\n",
    "        self.cdf = cdf\n",
    "\n",
    "    def sample_nonneg(self, n: int, rng: np.random.Generator) -> np.ndarray:\n",
    "        u = rng.random(n)\n",
    "        idx = np.searchsorted(self.cdf, u, side=\"left\")\n",
    "        return self.ks[idx]\n",
    "\n",
    "def sample_discrete_gaussian_cdt(n: int, sigma: float, tail_sigma: float = 10.0,\n",
    "                                 rng: np.random.Generator | None = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Two-sided discrete Gaussian via CDT on the nonnegative side + random sign.\n",
    "    Returns integer samples with stddev approximately sigma (tail truncated).\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    table = GaussianCDTTable(sigma=sigma, tail_sigma=tail_sigma)\n",
    "    k = table.sample_nonneg(n, rng)\n",
    "    print(k)\n",
    "    # random sign for k>0 (k=0 stays 0)\n",
    "    s = rng.integers(0, 2, size=n, dtype=np.int8) * 2 - 1  # in {-1, +1}\n",
    "    print(s)\n",
    "    x = (k * s).astype(np.int64)\n",
    "    x[k == 0] = 0\n",
    "    print(x)\n",
    "    return x\n",
    "\n",
    "# ------------------------------\n",
    "# Ternary sampler\n",
    "# ------------------------------\n",
    "def sample_ternary(n: int,\n",
    "                   p_minus: float = 0.25,\n",
    "                   p_zero: float = 0.50,\n",
    "                   p_plus: float = 0.25,\n",
    "                   rng: np.random.Generator | None = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ternary sampling for coefficients in {-1, 0, +1} with given probabilities.\n",
    "    Probabilities must sum to 1. Vectorized.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    if abs((p_minus + p_zero + p_plus) - 1.0) > 1e-12:\n",
    "        raise ValueError(\"Probabilities must sum to 1.\")\n",
    "    edges = np.array([p_minus, p_minus + p_zero], dtype=np.float64)\n",
    "    u = rng.random(n)\n",
    "    out = np.empty(n, dtype=np.int8)\n",
    "    out[:] = 1\n",
    "    out[u < edges[0]] = -1\n",
    "    out[(u >= edges[0]) & (u < edges[1])] = 0\n",
    "    return out.astype(np.int8)\n",
    "\n",
    "# ------------------------------\n",
    "# Uniform mod-q sampler\n",
    "# ------------------------------\n",
    "def sample_uniform_mod_q(n: int, q: int, use_barrett: bool = False,\n",
    "                         rng: np.random.Generator | None = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Uniform residues in [0, q). The hardware typically uses Barrett; for\n",
    "    Python we can use x % q or enable barrett for parity with RTL.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    # Draw 64-bit randoms (as if from a PRNG/TRNG) and reduce mod q\n",
    "    raw = rng.integers(0, 1 << 63, size=n, dtype=np.int64)\n",
    "    if use_barrett:\n",
    "        return barrett_reduce(raw, q)\n",
    "    else:\n",
    "        return (raw % q).astype(np.int64)\n",
    "\n",
    "# ------------------------------\n",
    "# Unified interface\n",
    "# ------------------------------\n",
    "class UnifiedSampler:\n",
    "    \"\"\"\n",
    "    Unified sampler with three modes: 'uniform', 'ternary', 'gaussian'.\n",
    "    Emulates a mode-selectable hardware sampler sharing one entropy source.\n",
    "    \"\"\"\n",
    "    def __init__(self, seed: int | None = None):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def sample(self, mode: str, n: int,\n",
    "               q: int | None = None,\n",
    "               p_minus: float = 0.25, p_zero: float = 0.50, p_plus: float = 0.25,\n",
    "               sigma: float = 3.2, tail_sigma: float = 10.0,\n",
    "               use_barrett: bool = False) -> np.ndarray:\n",
    "        mode = mode.lower()\n",
    "        if mode == \"uniform\":\n",
    "            if q is None:\n",
    "                raise ValueError(\"Uniform mode requires modulus q.\")\n",
    "            return sample_uniform_mod_q(n, q, use_barrett=use_barrett, rng=self.rng)\n",
    "        elif mode == \"ternary\":\n",
    "            return sample_ternary(n, p_minus=p_minus, p_zero=p_zero, p_plus=p_plus, rng=self.rng)\n",
    "        elif mode == \"gaussian\":\n",
    "            return sample_discrete_gaussian_cdt(n, sigma=sigma, tail_sigma=tail_sigma, rng=self.rng)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown mode. Use 'uniform', 'ternary', or 'gaussian'.\")\n",
    "\n",
    "# ------------------------------\n",
    "# Example usage / quick sanity checks\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    us = UnifiedSampler(seed=42)\n",
    "\n",
    "    # 1) Uniform mod-q\n",
    "    q = 281474976317441\n",
    "    u = us.sample(\"uniform\", n=2**16, q=q)\n",
    "    print(\"[Uniform] min,max =\", int(u.min()), int(u.max()))\n",
    "    print(\"[Uniform] unique coverage fraction ~\", np.ptp(u.astype(np.int64)) / (q - 1))\n",
    "\n",
    "    # 2) Ternary with 1:2:1\n",
    "    t = us.sample(\"ternary\", n=2**16, p_minus=0.25, p_zero=0.50, p_plus=0.25)\n",
    "    p_m = (t == -1).mean()\n",
    "    p_0 = (t == 0).mean()\n",
    "    p_p = (t == +1).mean()\n",
    "    print(f\"[Ternary] P(-1)={p_m:.4f}, P(0)={p_0:.4f}, P(+1)={p_p:.4f}\")\n",
    "\n",
    "    # 3) Discrete Gaussian via CDT\n",
    "    g = us.sample(\"gaussian\", n=2**16, sigma=3.2, tail_sigma=10.0)\n",
    "    print(f\"[Gaussian] mean={g.mean():.4f}, std‚âà{g.std(ddof=0):.4f}\")\n",
    "    # crude symmetry check:\n",
    "    print(f\"[Gaussian] P(x=0)={np.mean(g==0):.4f}, P(x>0)={np.mean(g>0):.4f}, P(x<0)={np.mean(g<0):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8eaa79fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Uniform] min,max: 3213173019 281473716442653\n",
      "[Ternary] P(-1)=0.250, P(0)=0.502, P(+1)=0.248\n",
      "[Gaussian] mean=0.007, std‚âà1.925\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# ------------------------------\n",
    "# Shared helper: Barrett reduce\n",
    "# ------------------------------\n",
    "def barrett_reduce64(x_u64: np.ndarray, q: int) -> np.ndarray:\n",
    "    k = 64\n",
    "    mu = (1 << k) // q\n",
    "    # big-int math via dtype=object, then cast back\n",
    "    t = ((x_u64.astype(object) * mu) >> k).astype(object)\n",
    "    r = (x_u64.astype(object) - t * q).astype(int)\n",
    "    # up to two corrections (safe)\n",
    "    r = np.where(r >= q, r - q, r)\n",
    "    r = np.where(r >= q, r - q, r)\n",
    "    r = np.where(r < 0, r + q, r)\n",
    "    return r.astype(np.int64)\n",
    "\n",
    "# ------------------------------\n",
    "# Shared helper: CDT (integer)\n",
    "# T has sentinel T[0]=0; entries in [0, 2^lam-1]\n",
    "# ------------------------------\n",
    "def build_cdt_int(sigma: float, tail_sigma: float = 10.0, lam: int = 64) -> np.ndarray:\n",
    "    tmax = max(20, int(math.ceil(tail_sigma * sigma)))\n",
    "    k = np.arange(0, tmax + 1, dtype=np.int64)  # nonnegative indices\n",
    "    rho = np.exp(-math.pi * (k.astype(np.float64) ** 2) / (sigma ** 2))\n",
    "    p = rho / rho.sum()                          # normalize nonnegative side\n",
    "    cdf = np.minimum(np.cumsum(p), 1.0)\n",
    "    T = np.minimum((cdf * (1 << lam)).astype(np.uint64), (1 << lam) - 1)\n",
    "    # prepend sentinel so search returns the correct bucket\n",
    "    T = np.concatenate(([np.uint64(0)], T))\n",
    "    return T  # length = tmax+2 (with sentinel)\n",
    "\n",
    "# ------------------------------\n",
    "# Unified sampler (single datapath concept)\n",
    "# ------------------------------\n",
    "@dataclass\n",
    "class UnifiedSampler:\n",
    "    seed: int | None = None\n",
    "    lam: int = 64  # entropy word width\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.rng = np.random.default_rng(self.seed)\n",
    "        self._cdt_cache: dict[tuple[float,float,int], np.ndarray] = {}\n",
    "\n",
    "    def _entropy(self, n: int) -> np.ndarray:\n",
    "        return self.rng.integers(0, 1 << self.lam, size=n, dtype=np.uint64)\n",
    "\n",
    "    def sample(self,\n",
    "               mode: str,\n",
    "               n: int,\n",
    "               q: int | None = None,\n",
    "               # ternary probs:\n",
    "               p_minus: float = 0.25, p_zero: float = 0.50, p_plus: float = 0.25,\n",
    "               # gaussian params:\n",
    "               sigma: float = 3.2, tail_sigma: float = 10.0,\n",
    "               use_barrett: bool = False) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Single-function, single-entropy-stream sampler.\n",
    "        Arithmetic reuse:\n",
    "          - one RNG stream r (uint64)\n",
    "          - compare(r, t) primitives for ternary and CDT search\n",
    "          - optional Barrett reducer for uniform\n",
    "        \"\"\"\n",
    "        r = self._entropy(n)  # <-- one shared entropy stream (datapath source)\n",
    "        mode = mode.lower()\n",
    "\n",
    "        if mode == \"uniform\":\n",
    "            if q is None:\n",
    "                raise ValueError(\"Uniform mode requires modulus q.\")\n",
    "            # reuse: reduce r mod q\n",
    "            return barrett_reduce64(r, q) if use_barrett else (r % q).astype(np.int64)\n",
    "\n",
    "        elif mode == \"ternary\":\n",
    "            if abs((p_minus + p_zero + p_plus) - 1.0) > 1e-12:\n",
    "                raise ValueError(\"Probabilities must sum to 1.\")\n",
    "            # thresholds scaled to 2^lam (shared compare primitive)\n",
    "            t1 = int(np.floor(p_minus * (1 << self.lam)))\n",
    "            t2 = int(np.floor((p_minus + p_zero) * (1 << self.lam)))\n",
    "            out = np.ones(n, dtype=np.int8)   # default +1\n",
    "            out[r < t1] = -1\n",
    "            mask_mid = (r >= t1) & (r < t2)\n",
    "            out[mask_mid] = 0\n",
    "            return out.astype(np.int8)\n",
    "\n",
    "        elif mode == \"gaussian\":\n",
    "            # get/build CDT integer thresholds once (reuse across calls)\n",
    "            key = (round(sigma, 6), round(tail_sigma, 6), self.lam)\n",
    "            T = self._cdt_cache.get(key)\n",
    "            if T is None:\n",
    "                T = build_cdt_int(sigma, tail_sigma, self.lam)\n",
    "                self._cdt_cache[key] = T\n",
    "            # vectorized binary search on integer thresholds using same r\n",
    "            # side='right' returns smallest idx with T[idx] > r  (equivalently r < T[idx])\n",
    "            idx = np.searchsorted(T, r, side='right')\n",
    "            # random sign reusing bits of r (LSB), zero stays zero\n",
    "            s = ((r & 1).astype(np.int8) * 2 - 1)  # {-1,+1}\n",
    "            x = (idx.astype(np.int64) * s.astype(np.int64))\n",
    "            x[idx == 0] = 0\n",
    "            return x\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown mode. Use 'uniform', 'ternary', or 'gaussian'.\")\n",
    "\n",
    "# ------------------------------\n",
    "# Example quick check\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    us = UnifiedSampler(seed=42)\n",
    "\n",
    "    # Uniform (uses same r stream conceptually)\n",
    "    q = 281_474_976_317_441\n",
    "    u = us.sample(\"uniform\", n=1<<16, q=q)\n",
    "    print(\"[Uniform] min,max:\", int(u.min()), int(u.max()))\n",
    "\n",
    "    # Ternary 1:2:1\n",
    "    t = us.sample(\"ternary\", n=1<<16, p_minus=0.25, p_zero=0.50, p_plus=0.25)\n",
    "    print(f\"[Ternary] P(-1)={(t==-1).mean():.3f}, P(0)={(t==0).mean():.3f}, P(+1)={(t==1).mean():.3f}\")\n",
    "\n",
    "    # Gaussian via CDT (integer table + search on r)\n",
    "    g = us.sample(\"gaussian\", n=1<<16, sigma=3.2, tail_sigma=10.0)\n",
    "    print(f\"[Gaussian] mean={g.mean():.3f}, std‚âà{g.std(ddof=0):.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dislab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
